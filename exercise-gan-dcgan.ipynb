{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - GANs for image generation \n",
    "\n",
    "1. Train a GAN on CIFAR-10 to generate images.\n",
    "1. Generate images using your trained GAN, interpolating over the latent space. Does it appear meaningful? Try such things as changing only one of the dimensions and keeping the rest fixed, trying to find an interpretation of the specific factor.\n",
    "1. (Bonus): Modify your GAN to be conditional. This means that the label information should now be provided as one of the inputs for the generator and as one of the targets for the discriminator.\n",
    "\n",
    "**Note**: You are unlikely to have time for the training to take place during class, so treat the exercise primarily as reaching the point where training is possible. Then, you can take the time at a later point. Try to solve **1** up to the point where training can start, and then use the rest as additional exercises post-lecture.\n",
    "\n",
    "**Hint**: Consider looking at https://www.tensorflow.org/tutorials/generative/dcgan, as they go through many of the same steps.\n",
    "\n",
    "**See slides for more details!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "You do not have (but are of course welcome) to change any of the setup code.\n",
    "\n",
    "Note that we use 1 to indicate \"real\" data and 0 to indicate \"fake\" data for the discriminator.\n",
    "\n",
    "In the loss of the generator, this is \"reversed\", i.e. fake data is 1. This is since it needs to learn to create fake data that the generator believes is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = (x_train / 127.5) - 1, (x_test / 127.5) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def eval_generator(generator, discriminator, fixed_noise):\n",
    "    gen_predictions = generator(fixed_noise, training=False)\n",
    "    \n",
    "    dis_predictions = discriminator.predict(generator(tf.random.normal([256, NOISE_DIM]), training=False))\n",
    "    dis_acc = round(np.mean(dis_predictions < 0.5) * 100, 2)\n",
    "    \n",
    "    print(f'Discriminator accuracy on fake images: {dis_acc}%.')\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(gen_predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((gen_predictions[i] + 1)/2)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Train a GAN on CIFAR-10 to generate images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some settings. Feel free to change them if you want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NOISE_DIM = 20\n",
    "fixed_noise = tf.random.normal([16, NOISE_DIM])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(60_000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by defining the generator and discriminator, as well as their optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.models.Sequential([\n",
    "    # NOTES: Must have input shape to match noise dimension and output shape (32, 32, 3)\n",
    "])\n",
    "generator.summary()\n",
    "\n",
    "discriminator = tf.keras.models.Sequential([\n",
    "    # NOTES: Must have input shape (32, 32, 3) and output shape 1 (dense layer with 1 node and NO activation)\n",
    "])\n",
    "discriminator.summary()\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us proceed by defining the training-step function we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_generator(generator, discriminator, fixed_noise)\n",
    "\n",
    "for epoch in range(40):\n",
    "    for train_x in train_dataset:\n",
    "        train_step(train_x)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    eval_generator(generator, discriminator, fixed_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Generate images using your trained GAN, interpolating over the latent space. Does it appear meaningful? Try such things as changing only one of the dimensions and keeping the rest fixed, trying to find an interpretation of the specific factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate one sample of noise, and then changing the first factor of that to produce a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, NOISE_DIM]).numpy()\n",
    "generated_images = generator.predict(noise)\n",
    "plt.imshow((generated_images[0] + 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_latent = np.concatenate([noise.copy() for _ in range(16)])\n",
    "noise_latent[:, 0] = np.linspace(-3, 3, len(noise_latent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images_latent = generator.predict(noise_latent)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "for i in range(generated_images_latent.shape[0]):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow((generated_images_latent[i] + 1)/2)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems this dimension has a lot to do with color, but also some structure (see e.g. the very top of the image, goes from quite sharp to more blurry).\n",
    "\n",
    "Let us try with other dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "(Bonus): Modify your GAN to be conditional. This means that the label information should now be provided as one of the inputs for the generator and as one of the targets for the discriminator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
